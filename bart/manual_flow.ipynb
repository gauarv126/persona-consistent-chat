{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BartTokenizer, BartModel\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartModel.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "# Input sentence\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "# 1. Run through encoder\n",
    "encoder_outputs = model.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "encoder_hidden_states = encoder_outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.decoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder_hidden_states[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Taking last\n",
    "h_z = encoder_hidden_states[:, 0, :]\n",
    "h_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartEncoder(\n",
       "  (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
       "  (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x BartEncoderLayer(\n",
       "      (self_attn): BartSdpaAttention(\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation_fn): GELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartDecoder(\n",
       "  (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
       "  (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x BartDecoderLayer(\n",
       "      (self_attn): BartSdpaAttention(\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (activation_fn): GELUActivation()\n",
       "      (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder_attn): BartSdpaAttention(\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartDecoderLayer(\n",
      "  (self_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (activation_fn): GELUActivation()\n",
      "  (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (encoder_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "BartDecoderLayer(\n",
      "  (self_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (activation_fn): GELUActivation()\n",
      "  (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (encoder_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "BartDecoderLayer(\n",
      "  (self_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (activation_fn): GELUActivation()\n",
      "  (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (encoder_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "BartDecoderLayer(\n",
      "  (self_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (activation_fn): GELUActivation()\n",
      "  (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (encoder_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "BartDecoderLayer(\n",
      "  (self_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (activation_fn): GELUActivation()\n",
      "  (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (encoder_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "BartDecoderLayer(\n",
      "  (self_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (activation_fn): GELUActivation()\n",
      "  (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (encoder_attn): BartSdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for decoder_layer in model.decoder.layers:\n",
    "    print(decoder_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "decoder_outputs = model.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=attention_mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prepare decoder input: <s> token\n",
    "decoder_input_ids = tokenizer(\"<s>\", return_tensors=\"pt\").input_ids\n",
    "decoder_attention_mask = torch.ones_like(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.embed_tokens(decoder_input_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.embed_positions(decoder_input_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = model.decoder.embed_tokens(decoder_input_ids) + model.decoder.embed_positions(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Convert decoder input tokens into embeddings\n",
    "hidden_states = model.decoder.embed_tokens(decoder_input_ids) + model.decoder.embed_positions(decoder_input_ids)\n",
    "\n",
    "# 2. Expand encoder attention mask for cross-attention\n",
    "def expand_mask(mask, dtype=torch.float32, tgt_len=None):\n",
    "    \"\"\"Expands the encoder attention mask for cross-attention in the decoder.\"\"\"\n",
    "    mask = mask[:, None, None, :]  # Shape: (batch_size, 1, 1, encoder_seq_len)\n",
    "    if tgt_len is not None:\n",
    "        mask = mask.expand(-1, -1, tgt_len, -1)  # Expand for target sequence length\n",
    "    return mask.to(dtype)\n",
    "\n",
    "encoder_attention_mask = expand_mask(attention_mask, dtype=torch.float32, tgt_len=decoder_input_ids.shape[1])\n",
    "\n",
    "# 3. Process each decoder layer (self-attention + cross-attention)\n",
    "for decoder_layer in model.decoder.layers:\n",
    "    hidden_states = decoder_layer(\n",
    "        hidden_states,                      # Decoder input embeddings\n",
    "        encoder_hidden_states=encoder_hidden_states,  # Encoder last hidden state\n",
    "        encoder_attention_mask=encoder_attention_mask,  # Mask for cross-attention\n",
    "        past_key_value=None,  \n",
    "        use_cache=False,  \n",
    "        output_attentions=False  \n",
    "    )[0]  # Extract the hidden state from the tuple\n",
    "\n",
    "# 4. Apply final LayerNorm\n",
    "hidden_states = model.decoder.layernorm_embedding(hidden_states)\n",
    "\n",
    "# 5. (Optional) Generate token logits\n",
    "# logits = model.lm_head(hidden_states)  # Get token probabilities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmedr_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
